# Introduction à l'apprentissage automatique

[Cliquez Ici pour lire le document sous format Jupyter Nootebook](livre.ipynb)

Sommaire:
- [Chapitre I: Introduction](#chapitre-i-introduction)
- [Chapitre II: Préparation de données](#chapitre-ii-préparation-de-données)
- [Chapitre III: Classification naïve bayésienne](#chapitre-iii-classification-naïve-bayésienne)
- [Chapitre IV: Machine à vecteurs de support](#chapitre-iv-machine-à-vecteurs-de-support)
- [Chapitre V: Arbre de décision](#chapitre-v-arbre-de-décision)
- [Chapitre VI: Régression linéaire](#chapitre-vi-régression-linéaire)
- [Chapitre VII: Régression logistique](#chapitre-vii-régression-logistique)
- [Chapitre VIII: Perceptron](#chapitre-viii-perceptron)
- [Chapitre IX: Réseau de neurones artificiels](#chapitre-ix-réseau-de-neurones-artificiels)
- [Chapitre X: Regroupement K-Means](#chapitre-x-regroupement-k-means)
- [Chapitre XI: Auto-encodeurs (Maybe not!!)](#chapitre-XI: Auto-encodeurs)
- [Chapitre XII: Apprentissage par renforcement](#chapitre-xii-apprentissage-par-renforcement)

## Chapitre I: Introduction

### I-1 Motivation

- Certaines tâches sont difficiles à programmer manuellement: Reconnaissance de formes, Traduction par machine, Reconnaissance de la parole, Aide à la décision, etc.
- Les données sont disponibles, qui peuvent être utilisé pour estimer la fonction de notre tâche.

### I-2 Applications

- Santé:
  - Watson santé de IBM: https://www.ibm.com/watson/health/
  - Projet Hanover de Microsoft: https://hanover.azurewebsites.net
  - DeepMind santé de Google: https://deepmind.com/applied/deepmind-health/

- Finance : Prévention de fraude, management de risques, prédiction des investissements, etc.
- Domaine légal : cas de CaseText https://casetext.com
- Traduction: Google traslate https://translate.google.com/
- ... TO BE CONTINUED

### I-3 Types des algorithmes d'apprentissage

#### I-3-1 Apprentissage supervisé

##### Classification

##### Régression

#### I-3-2 Apprentissage non supervisé

##### Clustering (Regroupement)

##### Réduction de dimension

#### I-3-3 Apprentissage par renforcement  

### I-4 Limites de l'apprentissage automatique

### I-5 Outils de l'apprentissage automatique


## Chapitre II: Préparation de données

### II-1

### II-2

### Bibliographie

- https://developers.google.com/machine-learning/data-prep/
- https://machinelearningmastery.com/how-to-prepare-data-for-machine-learning/
- https://www.altexsoft.com/blog/datascience/preparing-your-dataset-for-machine-learning-8-basic-techniques-that-make-your-data-better/


## Chapitre III: Classification naïve bayésienne

### III-1 Classification

$ P(A|B) = \frac{P(B|A) P(A)}{P(B)} $

### III-2 Apprentissage (Estimation des paramètres du modèle)

#### Loi multinomiale
valeurs discrètes

#### Loi de Bernoulli
caractéristiques binaires

#### Loi normal
valeurs continues

### III-3 Application (Points forts)

### III-4 Limites

### Bobliographie

- https://towardsdatascience.com/multinomial-naive-bayes-classifier-for-text-analysis-python-8dd6825ece67
- https://syncedreview.com/2017/07/17/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation/
- https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
- https://www.geeksforgeeks.org/naive-bayes-classifiers/
- https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c

## Chapitre IV: Machine à vecteurs de support

## Chapitre V: Machine à vecteurs de support

## Chapitre VI: Régression linéaire

## Chapitre VII: Régression logistique

## Chapitre VIII: Perceptron

## Chapitre IX: Réseau de neurones artificiels

## Chapitre X: Regroupement

## X-1 Regroupement hiérarchique
## X-2 K-Means

### Bibliographie

- https://towardsdatascience.com/unsupervised-learning-with-python-173c51dc7f03

## Chapitre XI: Auto-encodeurs (Maybe not!!)

## Chapitre XII: Apprentissage par renforcement
